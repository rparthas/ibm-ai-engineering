{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Implementing Diffusion Models**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn how to implement, train, and evaluate diffusion models using Keras. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will: \n",
    "- Acquire practical understanding of diffusion model architectures, data processing, model training, and performance evaluation \n",
    "- Implement, train, and evaluate diffusion models using Keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites \n",
    "\n",
    "- Basic understanding of Python and Keras \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps \n",
    "\n",
    "#### Step 1: Preprocess data \n",
    "\n",
    "Prepare the MNIST data set for training by normalizing the pixel values and reshaping the images to have a single color channel. Normalization helps in faster convergence during training, and reshaping is required because the input layer of your diffusion model expects a three-dimensional tensor. \n",
    "\n",
    "**1. Load and preprocess the MNIST data set:**\n",
    "\n",
    "- Use Keras to load the MNIST data set. \n",
    "- Normalize the image pixel values to the range [0, 1]. \n",
    "\n",
    "**2. Reshape the Data:**\n",
    "- Expand the dimensions of the images to match the input shape required by the model (28x28x1). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow-cpu==2.16.2\n",
    "\n",
    "import os\n",
    "# Suppress oneDNN optimizations and lower TensorFlow logging level\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.3.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Downloading numpy-2.3.2-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp313-cp313-macosx_10_13_universal2.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/rparthas/.local/share/mise/installs/python/3.13.5/lib/python3.13/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rparthas/.local/share/mise/installs/python/3.13.5/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading matplotlib-3.10.6-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp313-cp313-macosx_11_0_arm64.whl (274 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp313-cp313-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp313-cp313-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, python-dateutil, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.10.6 pillow-11.3.0 pyparsing-3.2.3 python-dateutil-2.9.0.post0 six-1.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data set  \n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values  \n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# Expand dimensions to match the input shape (28, 28, 1)  \n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Add noise to the data\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Clip the values to be within the range [0, 1]\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Build the diffusion model \n",
    "\n",
    "Build a simple diffusion model with an encoder that compresses the input image into a latent representation and a decoder that reconstructs the image from this representation. The model is compiled with the Adam optimizer and binary cross-entropy loss. \n",
    "\n",
    "**1. Define the encoder:**\n",
    "- Create an input layer with the shape (28, 28, 1). \n",
    "- Add two Conv2D layers with increasing filter sizes and ReLU activation. \n",
    "\n",
    "**2. Define the bottleneck:**\n",
    "- Add a flattened layer followed by a dense layer with ReLU activation. \n",
    "\n",
    "**3. Define the decoder:**\n",
    "- Add a Dense layer to expand the bottleneck representation.  \n",
    "- Reshape the output to match the original image dimensions.  \n",
    "- Add two Conv2DTranspose layers with decreasing filter sizes and ReLU activation.\n",
    "  \n",
    "**4. Compile the model:**\n",
    "- Use the Adam optimizer and binary cross-entropy loss. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,630,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">145</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m1,605,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │     \u001b[38;5;34m1,630,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m4,624\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m145\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,255,233</span> (12.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,255,233\u001b[0m (12.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,255,233</span> (12.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,255,233\u001b[0m (12.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the diffusion model architecture with reduced complexity\n",
    "input_layer = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)  # Reduced filters\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)  # Reduced size\n",
    "x = Dense(28*28*32, activation='relu')(x)  # Reduced size\n",
    "x = Reshape((28, 28, 32))(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "x = Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "diffusion_model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile the model with mixed precision and a different loss function\n",
    "diffusion_model.compile(optimizer='adam', loss='mean_squared_error')  # Using MSE for regression tasks\n",
    "\n",
    "# Summary of the optimized model\n",
    "diffusion_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Add noise to the data \n",
    "\n",
    "Add random noise to the data set to simulate the diffusion process: \n",
    "- Add Gaussian noise to the training and test data sets.  \n",
    "- Clip the values to ensure they remain within the valid range [0, 1].  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache and prefetch the data using TensorFlow data pipelines for faster loading\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_noisy, x_train))\n",
    "train_dataset = train_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test_noisy, x_test))\n",
    "val_dataset = val_dataset.cache().batch(64).prefetch(tf.data.AUTOTUNE)  # Reduced batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Train the diffusion model \n",
    "\n",
    "Train the diffusion model to denoise the MINIST images. Use the noisy images as input and the original images as the target, learning to reverse the noise addition process. \n",
    "- Use the ‘fit’ method to train the model on the noisy training data. \n",
    "- Set the number of epochs to 50 and the batch size to 128. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - loss: 0.0327 - val_loss: 0.0164\n",
      "Epoch 2/3\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - loss: 0.0131 - val_loss: 0.0132\n",
      "Epoch 3/3\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 41ms/step - loss: 0.0113 - val_loss: 0.0124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x141f356a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement early stopping based on validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping and smaller batch size\n",
    "diffusion_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    shuffle=True,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Evaluate the diffusion model \n",
    "\n",
    "Evaluate the performance of the trained diffusion model by predicting the denoised images and visualizing the results. Comparing the original, noisy, and denoised images will help you understand how well the model has learned to remove noise from the images. \n",
    "\n",
    "**1. Reconstruct images:**\n",
    "- Use the diffusion model to predict the denoised test images.  \n",
    "- Compare the original, noisy, and denoised images. \n",
    "\n",
    "**2. Visualize the results:**\n",
    "- Plot a few examples of original, noisy, and denoised images side by side. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict the denoised images\n",
    "denoised_images = diffusion_model.predict(x_test_noisy)\n",
    "\n",
    "# Visualize the results\n",
    "n = 10  # Number of digits to display\n",
    "plt.figure(figsize=(20, 6))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display noisy\n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display denoised\n",
    "    ax = plt.subplot(3, n, i + 1 + 2*n)\n",
    "    plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Fine-tune the diffusion model \n",
    "\n",
    "Fine-tune the diffusion model by unfreezing some layers and retraining the model to improve its performance. \n",
    "\n",
    "\n",
    "**1. Freeze the model layers:**\n",
    "- Freeze all the layers of the encoder.\n",
    "\n",
    "**2. Check the Status:** \n",
    "- Checking the trainable status of each layer.\n",
    "\n",
    "**3. Unfreeze the model layers:** \n",
    "- Unfreeze the last few layers of the model to allow them to be retrained. \n",
    "\n",
    "**4. Compile and train the model:** \n",
    "- Recompile the model. \n",
    "- Train the model again for an additional 10 epochs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers \n",
    "for layer in diffusion_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: input_layer — Trainable: False\n",
      "Layer 1: conv2d — Trainable: False\n",
      "Layer 2: conv2d_1 — Trainable: False\n",
      "Layer 3: flatten — Trainable: False\n",
      "Layer 4: dense — Trainable: False\n",
      "Layer 5: dense_1 — Trainable: False\n",
      "Layer 6: reshape — Trainable: False\n",
      "Layer 7: conv2d_transpose — Trainable: False\n",
      "Layer 8: conv2d_transpose_1 — Trainable: False\n",
      "Layer 9: conv2d_2 — Trainable: False\n"
     ]
    }
   ],
   "source": [
    "# Check trainable status of each layer\n",
    "for i, layer in enumerate(diffusion_model.layers):\n",
    "    print(f\"Layer {i}: {layer.name} — Trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 25ms/step - loss: 0.0930 - val_loss: 0.0958\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - loss: 0.0923 - val_loss: 0.0955\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 27ms/step - loss: 0.0920 - val_loss: 0.0953\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 27ms/step - loss: 0.0919 - val_loss: 0.0953\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 27ms/step - loss: 0.0917 - val_loss: 0.0951\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - loss: 0.0917 - val_loss: 0.0952\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 27ms/step - loss: 0.0916 - val_loss: 0.0950\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 29ms/step - loss: 0.0916 - val_loss: 0.0954\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 32ms/step - loss: 0.0915 - val_loss: 0.0950\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 29ms/step - loss: 0.0915 - val_loss: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x141f607d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfreeze the top layers of the model\n",
    "for layer in diffusion_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model again\n",
    "diffusion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the model again\n",
    "diffusion_model.fit(x_train_noisy, x_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_noisy, x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### Exercise 1: Modify the noise factor  \n",
    "\n",
    "#### Objective: \n",
    "- Change the noise factor and see how it affects the model’s ability to denoise images.\n",
    "#### Instructions:  \n",
    "1. Change the noise factor to 0.3.  \n",
    "2. Add noise to the training and test data sets with the new noise factor.  \n",
    "3. Retrain the model with the new noisy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m 24/469\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:29\u001b[0m 471ms/step - loss: 0.0875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m x_test_noisy = np.clip(x_test_noisy, \u001b[32m0.\u001b[39m, \u001b[32m1.\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Retrain the model  \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mdiffusion_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "noise_factor = 0.3\n",
    "\n",
    "# Add noise to the data with the new noise factor  \n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "\n",
    "# Clip the values to be within the range [0, 1]  \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# Retrain the model  \n",
    "diffusion_model.fit(x_train_noisy, x_train,epochs=50,batch_size=128, \n",
    "    shuffle=True,validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Modify the noise factor to 0.3  \n",
    "noise_factor = 0.3  \n",
    "   \n",
    "# Add noise to the data with the new noise factor  \n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)  \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)  \n",
    "  \n",
    "# Clip the values to be within the range [0, 1]  \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)  \n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)  \n",
    "   \n",
    "# Retrain the model  \n",
    "diffusion_model.fit(x_train_noisy, x_train,    \n",
    "                    epochs=50,    \n",
    "                    batch_size=128,    \n",
    "                    shuffle=True,    \n",
    "                    validation_data=(x_test_noisy, x_test))  \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Add more layers to the model  \n",
    "\n",
    "#### Objective: \n",
    "- Experiment with adding more layers to the model to see how it affects performance.\n",
    "\n",
    "#### Instructions:\n",
    "1. Add an additional Conv2D layer with 128 filters in the encoder.  \n",
    "2. Add an additional Conv2DTranspose layer with 128 filters in the decoder.  \n",
    "3. Rebuild, compile, and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,472,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_5              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m12,845,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │     \u001b[38;5;34m6,472,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_5              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │           \u001b[38;5;34m289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,576,961</span> (74.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,576,961\u001b[0m (74.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,576,961</span> (74.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,576,961\u001b[0m (74.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 542ms/step - loss: 0.1641 - val_loss: 0.1067\n",
      "Epoch 2/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 638ms/step - loss: 0.1029 - val_loss: 0.0996\n",
      "Epoch 3/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 685ms/step - loss: 0.0984 - val_loss: 0.0974\n",
      "Epoch 4/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 680ms/step - loss: 0.0956 - val_loss: 0.0968\n",
      "Epoch 5/50\n",
      "\u001b[1m203/469\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3:02\u001b[0m 686ms/step - loss: 0.0927"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m diffusion_model.summary()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Train the model  \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mdiffusion_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ibm-ai-engineering/.venv/lib/python3.13/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "input_layer = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(28*28*64, activation='relu')(x)\n",
    "x = Reshape((28, 28, 64))(x)\n",
    "x = Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "diffusion_model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile the model  \n",
    "diffusion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Summary of the model  \n",
    "diffusion_model.summary()\n",
    "\n",
    "# Train the model  \n",
    "diffusion_model.fit(x_train_noisy, x_train,epochs=50,batch_size=128,shuffle=True,validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# Define the modified diffusion model architecture with additional layers\n",
    "input_layer = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(28*28*64, activation='relu')(x)\n",
    "x = Reshape((28, 28, 64))(x)\n",
    "x = Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x) # Additional layer\n",
    "x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "diffusion_model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile the model  \n",
    "diffusion_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "   \n",
    "\n",
    "# Summary of the model  \n",
    "diffusion_model.summary()\n",
    "\n",
    "# Train the model  \n",
    "diffusion_model.fit(x_train_noisy, x_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_noisy, x_test))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Visualize the effect of noise  \n",
    "\n",
    "#### Objective: \n",
    "- Compare the impact of different noise levels on the denoising performance of the model.\n",
    "\n",
    "#### Instructions:  \n",
    "1. Add noise with different factors (e.g., 0.1, 0.5, 0.7) to the test data.  \n",
    "2. Use the model to predict the denoised images for each noise level.  \n",
    "3. Visualize the original, noisy, and denoised images side by side for each noise level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "\n",
    "# Function to add noise and predict denoised images\n",
    "def add_noise_and_predict(noise_factor):\n",
    "    x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "    x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "    denoised_images = diffusion_model.predict(x_test_noisy)\n",
    "    return x_test_noisy, denoised_images\n",
    "\n",
    "# Noise levels to test\n",
    "noise_levels = [0.1, 0.5, 0.7]\n",
    "   \n",
    "# Visualize the results\n",
    "n = 5  # Number of digits to display\n",
    "plt.figure(figsize=(20, 12))\n",
    "for idx, noise_factor in enumerate(noise_levels):\n",
    "    x_test_noisy, denoised_images = add_noise_and_predict(noise_factor)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Display original\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + idx * 3 * n)\n",
    "        plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(f'Original (Noise: {noise_factor})')\n",
    "          \n",
    "        # Display noisy\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + n + idx * 3 * n)\n",
    "        plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "\n",
    "\n",
    "        # Display denoised\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + 2 * n + idx * 3 * n)\n",
    "        plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "\n",
    "# Function to add noise and predict denoised images\n",
    "def add_noise_and_predict(noise_factor):\n",
    "    x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "    x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "    denoised_images = diffusion_model.predict(x_test_noisy)\n",
    "    return x_test_noisy, denoised_images\n",
    "\n",
    "# Noise levels to test\n",
    "noise_levels = [0.1, 0.5, 0.7]\n",
    "   \n",
    "# Visualize the results\n",
    "n = 5  # Number of digits to display\n",
    "plt.figure(figsize=(20, 12))\n",
    "for idx, noise_factor in enumerate(noise_levels):\n",
    "    x_test_noisy, denoised_images = add_noise_and_predict(noise_factor)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Display original\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + idx * 3 * n)\n",
    "        plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(f'Original (Noise: {noise_factor})')\n",
    "          \n",
    "        # Display noisy\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + n + idx * 3 * n)\n",
    "        plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "\n",
    "\n",
    "        # Display denoised\n",
    "        ax = plt.subplot(3 * len(noise_levels), n, i + 1 + 2 * n + idx * 3 * n)\n",
    "        plt.imshow(denoised_images[i].reshape(28, 28), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)  \n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary  \n",
    "\n",
    "By completing these exercises, students will:  \n",
    "1. Understand the impact of different noise factors on the model’s denoising capabilities.\n",
    "2. Learn how adding more layers to the model affects its performance.\n",
    "3. Visualize how different levels of noise affect the denoising results of the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Congratulations! You have gained practical experience in implementing diffusion models using Keras. You learned how to preprocess data, construct a basic diffusion model architecture, add noise to the data set, train the model, and evaluate its performance. Additionally, you explored fine-tuning techniques to enhance the model’s performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "prev_pub_hash": "27706737bf8740a3a1a40766707767fe01f58bbbeb5b1152a891f5d820b8a925"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
